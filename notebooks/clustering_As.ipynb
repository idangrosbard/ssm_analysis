{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "441aac74edba7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from transformers import MambaForCausalLM\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5267123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluate_model import get_tokenizer_and_model\n",
    "from scripts.plot_a_vals_distr import collect_and_stack_A_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89525694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "_, model = get_tokenizer_and_model(\"mamba\", '2.8B')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13042d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_A_logs, layer_indices, position_indices = collect_and_stack_A_logs(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f814fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data, features_to_add, feature_dict=None):\n",
    "    if feature_dict is None:\n",
    "        feature_dict = {}\n",
    "    features_to_add = [f for f in features_to_add if f not in feature_dict]\n",
    "    if 'original' in features_to_add:\n",
    "        feature_dict['original'] = data\n",
    "    if 'L1_norm' in features_to_add:\n",
    "        feature_dict['L1_norm'] = np.linalg.norm(data, ord=1, axis=1, keepdims=True)\n",
    "    if 'L_infinity_norm' in features_to_add:\n",
    "        feature_dict['L_infinity_norm'] = np.linalg.norm(data, ord=np.inf, axis=1, keepdims=True)\n",
    "    if 'top_2_pca' in features_to_add:\n",
    "        pca = PCA(n_components=min(data.shape[1], 5))  # Compute more PCA components\n",
    "        pca_features = pca.fit_transform(data)\n",
    "        top_2_indices = np.argsort(-np.abs(pca_features), axis=1)[:, :2]  # Get indices of top 2 absolute values per row\n",
    "        top_2_pca_features = np.take_along_axis(pca_features, top_2_indices, axis=1)  # Select the top 2 PCA components\n",
    "        feature_dict['top_2_pca'] = top_2_pca_features\n",
    "        feature_dict['pca1'] = pca_features[:, 0].reshape(-1, 1)\n",
    "        feature_dict['pca2'] = pca_features[:, 1].reshape(-1, 1)\n",
    "    if 'skewness' in features_to_add:\n",
    "        feature_dict['skewness'] = skew(data, axis=1).reshape(-1, 1)\n",
    "    if 'kurtosis' in features_to_add:\n",
    "        feature_dict['kurtosis'] = kurtosis(data, axis=1).reshape(-1, 1)\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97950a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6925c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_features = compute_features(stacked_A_logs, features_to_add=['original', 'L1_norm', 'L_infinity_norm', 'top_2_pca', 'skewness', 'kurtosis'], feature_dict=enriched_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "414e5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_features_names = ['L1_norm', 'L_infinity_norm', 'skewness', 'kurtosis', 'pca1', 'pca2']\n",
    "# Create a DataFrame for enriched features\n",
    "enriched_df = pd.DataFrame({\n",
    "    **{\n",
    "        f'{feature}': enriched_features[feature].flatten()\n",
    "        for feature \n",
    "        in enriched_features_names\n",
    "    },\n",
    "    'Layer Index': layer_indices,\n",
    "    'Layer Index str': [f'Layer {i}' for i in layer_indices],\n",
    "    'Position Index': position_indices\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce58b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df.to_csv('A_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2c5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3561208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_interactions(data, feature1, feature2):\n",
    "    n_layers = len(data['Layer Index'].unique())\n",
    "    colorscale = px.colors.sample_colorscale(\n",
    "        px.colors.sequential.Plasma, \n",
    "        [(i/n_layers) for i in range(n_layers)]\n",
    "        )\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        data, \n",
    "        x=feature1, y=feature2,\n",
    "        color='Layer Index str',\n",
    "        color_discrete_sequence=colorscale,\n",
    "        hover_data=['Position Index', 'Layer Index', 'L1_norm', 'L_infinity_norm', 'skewness', 'kurtosis', 'pca1', 'pca2'],\n",
    "        opacity=0.1,\n",
    "        title=f'{feature1} vs {feature2}'\n",
    "        )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_feature_interactions(enriched_df, 'L1_norm', 'L_infinity_norm')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f95c9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering with KMeans\n",
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(enriched_df[['L1_norm', 'L_infinity_norm', 'skewness', 'kurtosis', 'pca1', 'pca2']])\n",
    "enriched_df['Cluster_all_enriched'] = kmeans.labels_\n",
    "enriched_df['Cluster_all_enriched_str'] = [f'Cluster {i}' for i in kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e003db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot using Plotly\n",
    "fig = px.scatter(\n",
    "    enriched_df, x='L Infinity Norm', y='L1 Norm', color='Layer Index',\n",
    "    hover_data={'Position Index': True},\n",
    "    title='Distribution of Different Features',\n",
    "    labels={'L1 Norm': 'L1 Norm Feature'}\n",
    ")\n",
    "\n",
    "# Update layout to make Layer Index toggleable\n",
    "fig.update_traces(marker=dict(size=5), selector=dict(mode='markers'))\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title='Layer',\n",
    "        itemsizing='constant',\n",
    "        itemclick='toggleothers',  # Toggle visibility of other traces\n",
    "        itemdoubleclick='toggle'   # Toggle visibility of the clicked trace\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"feature_distribution.html\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd081d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"feature_distribution1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Collect A_log matrices\n",
    "A_logs = [model.backbone.layers[i].mixer.A_log.detach().numpy() for i in range(len(model.backbone.layers))]\n",
    "\n",
    "# Step 2: Stack into a single dataset\n",
    "A_logs_all= np.vstack(A_logs)\n",
    "\n",
    "# Optional: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "A_logs_all_scaled = scaler.fit_transform(A_logs_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Perform clustering\n",
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(A_logs_all_scaled)\n",
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ff12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Analyze clusters\n",
    "# Example: Get indices of data points in cluster 0\n",
    "cluster_0_indices = np.where(labels == 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map back to layers and positions\n",
    "layer_size = A_logs[0].shape[0]\n",
    "layer_indices = np.repeat(np.arange(len(A_logs)), layer_size)\n",
    "position_indices = np.tile(np.arange(layer_size), len(A_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a152981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "A_logs_pca = pca.fit_transform(A_logs_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'PCA Component 1': A_logs_pca[:, 0],\n",
    "    'PCA Component 2': A_logs_pca[:, 1],\n",
    "    'Cluster': labels,\n",
    "    'Layer Index': layer_indices,\n",
    "    'Position Index': position_indices\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d561e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using Plotly\n",
    "fig = px.scatter(\n",
    "    df, x='PCA Component 1', y='PCA Component 2', color='Cluster',\n",
    "    hover_data={'Layer Index': True, 'Position Index': True},\n",
    "    opacity=0.7,  # Add alpha to points\n",
    "    title='Clustering of A_log Matrices (PCA Reduced)',\n",
    "    labels={'PCA Component 1': 'PCA Component 1', 'PCA Component 2': 'PCA Component 2'}\n",
    ")\n",
    "fig.update_layout(legend_title_text='Cluster')  # Add legend title for interactivity\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34d254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b0015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b68ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ed362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in tqdm(enumerate(model.backbone.layers)):\n",
    "    for j in range(layer.mixer.A_log.shape[0]):\n",
    "        for k in range(layer.mixer.A_log.shape[1]):\n",
    "            vals['layer'].append(i)\n",
    "            vals['val'].append(layer.mixer.A_log[j,k].item())\n",
    "            vals['ssm_id'].append(j)\n",
    "            vals['ssm_id+layer'].append(f'{i}:{j}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24010fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(vals)\n",
    "min_val_per_ssm = df.groupby(['ssm_id', 'layer'])['val'].min().reset_index()\n",
    "\n",
    "# get min val\n",
    "min_vals = df.groupby(['ssm_id', 'layer'])['val'].min().reset_index()\n",
    "max_vals = df.groupby(['ssm_id', 'layer'])['val'].median().reset_index()\n",
    "min_max_vals = min_vals.merge(max_vals, on=['ssm_id', 'layer'], suffixes=('_min', '_max'))\n",
    "\n",
    "# plot scatter:\n",
    "min_max_vals['layer'] = min_max_vals['layer'].astype(str)\n",
    "n_layers = len(min_max_vals['layer'].unique())\n",
    "colorscale = px.colors.sample_colorscale(px.colors.sequential.Plasma, [i / n_layers for i in range(n_layers)])\n",
    "fig = px.scatter(min_max_vals, x='val_min', y='val_max', color='layer', color_discrete_sequence=colorscale)\n",
    "fig.update_layout(height=1000, width=1000)\n",
    "fig.write_html(f\"a_vals_min_max_categ_{model_size}.html\")\n",
    "\n",
    "\n",
    "import torch\n",
    "min_max_vals['val_min'] = -torch.exp(torch.from_numpy(min_max_vals['val_min'].to_numpy())).numpy()\n",
    "min_max_vals['val_max'] = -torch.exp(torch.from_numpy(min_max_vals['val_max'].to_numpy())).numpy()\n",
    "fig = px.scatter(min_max_vals, x='val_min', y='val_max', color='layer', color_discrete_sequence=colorscale)\n",
    "fig.update_layout(height=1000, width=1000)\n",
    "fig.write_html(f\"a_vals_min_max_categ_{model_size}_exp.html\")\n",
    "\n",
    "\n",
    "min_max_vals['val_min'] = torch.exp(torch.from_numpy(min_max_vals['val_min'].to_numpy())).numpy()\n",
    "min_max_vals['val_max'] = torch.exp(torch.from_numpy(min_max_vals['val_max'].to_numpy())).numpy()\n",
    "fig = px.scatter(min_max_vals, x='val_min', y='val_max', color='layer', color_discrete_sequence=colorscale)\n",
    "fig.update_layout(height=1000, width=1000)\n",
    "fig.write_html(f\"a_vals_min_max_categ_{model_size}_exp_exp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6383d6b-4fed-42c4-9664-b28e93563a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95867d2-2999-4468-b96f-9952c3c04510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

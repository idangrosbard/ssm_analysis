{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import pyrallis\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from src.consts import (\n",
    "    FILTERATIONS,\n",
    "    MODEL_SIZES_PER_ARCH_TO_MODEL_ID,\n",
    ")\n",
    "from src.types import DATASETS, MODEL_ARCH, DatasetArgs, TModelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    # model_arch: MODEL_ARCH = MODEL_ARCH.MINIMAL_MAMBA2_new\n",
    "    model_arch: MODEL_ARCH = MODEL_ARCH.MAMBA1\n",
    "    model_size: str = \"2.8B\"\n",
    "    dataset_args: DatasetArgs = pyrallis.field(\n",
    "        default=DatasetArgs(name=DATASETS.COUNTER_FACT, splits=\"all\"), is_mutable=True\n",
    "    )\n",
    "    filteration: str = FILTERATIONS.all_correct\n",
    "    _batch_size: int = 16  # Adjust based on GPU memory\n",
    "    output_file: Optional[Path] = None\n",
    "    with_slurm: bool = False\n",
    "    temperature = 1\n",
    "    top_k = 0\n",
    "    top_p = 1\n",
    "    window_size = 5\n",
    "    prompt_indices = [1,2,3,4,5]\n",
    "    knockout_map = {'last': ['last', 'first', \"subject\", \"relation\"], \n",
    "                    'subject': ['context', 'subject']}\n",
    "\n",
    "    output_dir: Optional[Path] = None\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        return (\n",
    "            1\n",
    "            if (\n",
    "                self.model_arch == MODEL_ARCH.MINIMAL_MAMBA2\n",
    "                or self.model_arch == MODEL_ARCH.MINIMAL_MAMBA2_new\n",
    "            )\n",
    "            else self._batch_size\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def model_id(self) -> TModelID:\n",
    "        return MODEL_SIZES_PER_ARCH_TO_MODEL_ID[self.model_arch][self.model_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "from torch import matmul, zeros_like\n",
    "\n",
    "from .. import KnockoutMode\n",
    "\n",
    "\n",
    "def knockout_scan(seq_len: int, ssm_state: Tensor, discrete_A: Tensor, discrete_B: Tensor, u: Tensor, C: Tensor, knocked_out_inputs: Iterable[int], affected_outputs: Iterable[int], knockout_mode: KnockoutMode, dtype) -> List[Tensor]:\n",
    "    deltaB_u = discrete_B * u[:, :, :, None].float()\n",
    "    knockout_state = zeros_like(ssm_state)\n",
    "    scan_outputs = []\n",
    "    for i in range(seq_len):\n",
    "        ssm_state = discrete_A[:, :, i, :] * ssm_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n",
    "        if i not in knocked_out_inputs:\n",
    "            knockout_state = discrete_A[:, :, i, :] * knockout_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n",
    "        elif i in knocked_out_inputs:\n",
    "            if knockout_mode == KnockoutMode.ZERO_ATTENTION:\n",
    "                knockout_state = discrete_A[:, :, i, :] * knockout_state\n",
    "            elif knockout_mode == KnockoutMode.ZERO_DELTA:\n",
    "                knockout_state = knockout_state\n",
    "        if i in affected_outputs:\n",
    "            scan_output = matmul(knockout_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n",
    "        else:\n",
    "            scan_output = matmul(ssm_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n",
    "        scan_outputs.append(scan_output[:, :, 0])\n",
    "\n",
    "    return scan_outputs\n",
    "\n",
    "\n",
    "def materialize_ssm_transition(A: torch.Tensor) -> torch.Tensor:\n",
    "    batch = A.shape[0]\n",
    "    D = A.shape[1]\n",
    "    T = A.shape[2]\n",
    "    N = A.shape[3]\n",
    "    A = A.transpose(-1,-2).repeat(1,1,1,T).reshape(batch,D,N,T,T).transpose(-1,-2)\n",
    "    A = torch.tril(A) + torch.triu(torch.ones_like(A),1)\n",
    "    A_cumprod = torch.cumprod(A, dim=-2)\n",
    "\n",
    "    transition_mat = A_cumprod.transpose(-2,-3)\n",
    "\n",
    "    return transition_mat\n",
    "\n",
    "\n",
    "def materialize_ssm_attention(A: Tensor, B: Tensor, C: Tensor, return_transition: bool) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]: \n",
    "    transition_mat = materialize_ssm_transition(A)\n",
    "\n",
    "    AB = (transition_mat * B.unsqueeze(-1))\n",
    "\n",
    "    out = torch.einsum('btn, bdtnq -> bdtq', C, AB)\n",
    "    \n",
    "    if return_transition:\n",
    "        return out, transition_mat\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def knockout_matrix(seq_len: int, discrete_A: Tensor, discrete_B: Tensor, u: Tensor, C: Tensor, knocked_out_inputs: Iterable[int], affected_outputs: Iterable[int], dtype) -> List[Tensor]:\n",
    "    attn = materialize_ssm_attention(discrete_A, discrete_B, C, False)\n",
    "    for i, j in zip(affected_outputs, knocked_out_inputs):\n",
    "        attn[:, :, i, j] = 0\n",
    "    outputs = attn * u[:, :, :, None].float()\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def knockout_scan(seq_len: int, ssm_state: Tensor, discrete_A: Tensor, deltaB_u: Tensor, C: Tensor, knocked_out_inputs: Iterable[int], affected_outputs: Iterable[int], dtype) -> List[Tensor]:\n",
    "    knockout_state = zeros_like(ssm_state)\n",
    "    scan_outputs = []\n",
    "    for i in range(seq_len):\n",
    "        ssm_state = discrete_A[:, :, i, :] * ssm_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n",
    "        print(ssm_state)\n",
    "        if i not in knocked_out_inputs:\n",
    "            knockout_state = discrete_A[:, :, i, :] * knockout_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n",
    "        elif i in knocked_out_inputs:\n",
    "            knockout_state = discrete_A[:, :, i, :] * knockout_state\n",
    "        if i in affected_outputs:\n",
    "            scan_output = matmul(knockout_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n",
    "        else:\n",
    "            scan_output = matmul(ssm_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n",
    "        scan_outputs.append(scan_output[:, :, 0])\n",
    "\n",
    "    return scan_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def scan(seq_len: int, ssm_state: Tensor, discrete_A: Tensor, deltaB_u: Tensor, C: Tensor, knocked_out_inputs: Iterable[int], affected_outputs: Iterable[int], dtype) -> List[Tensor]:\n",
    "    scan_outputs = []\n",
    "    for i in range(seq_len):\n",
    "        ssm_state = discrete_A[:, :, i, :] * ssm_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n",
    "        # print(ssm_state)\n",
    "        scan_output = matmul(ssm_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n",
    "        scan_outputs.append(scan_output[:, :, 0])\n",
    "\n",
    "    return scan_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch = 1\n",
    "d_intermediate = 1\n",
    "T = 5\n",
    "ssm_d = 8\n",
    "\n",
    "A = torch.ones((batch, d_intermediate, T, ssm_d)) # [batch, intermediate_size, seq_len, ssm_state_size]\n",
    "B = torch.ones((batch, d_intermediate, T, ssm_d)) # [batch, intermediate_size, seq_len, ssm_state_size]\n",
    "B = B / ssm_d\n",
    "C = torch.ones((batch, T, ssm_d)) # [batch, seq_len, intermediate_size, ssm_state_size]\n",
    "u = torch.Tensor([[[2**i for i in range(T)]]])    # [batch, seq_len, intermediate_size]\n",
    "\n",
    "Bu = B * u[:,:,:,None]\n",
    "\n",
    "state = torch.zeros(batch,d_intermediate,ssm_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]]])\n",
      "tensor([[[0.3750, 0.3750, 0.3750, 0.3750, 0.3750, 0.3750, 0.3750, 0.3750]]])\n",
      "tensor([[[0.8750, 0.8750, 0.8750, 0.8750, 0.8750, 0.8750, 0.8750, 0.8750]]])\n",
      "tensor([[[1.8750, 1.8750, 1.8750, 1.8750, 1.8750, 1.8750, 1.8750, 1.8750]]])\n",
      "tensor([[[3.8750, 3.8750, 3.8750, 3.8750, 3.8750, 3.8750, 3.8750, 3.8750]]])\n",
      "tensor([[[ 1.,  2.,  4.,  8., 16.]]])\n",
      "tensor([[[ 1.,  3.,  7., 15., 31.]]])\n",
      "tensor([[1.]]) 1\n",
      "tensor([[3.]]) 11\n",
      "tensor([[7.]]) 111\n",
      "tensor([[15.]]) 1111\n",
      "tensor([[24.]]) 11000\n"
     ]
    }
   ],
   "source": [
    "out = knockout_scan(T, state, A, Bu, C, [0,1,2], [4], torch.float)\n",
    "# out = scan(T, state, A, Bu, C, [1], [3], torch.float)\n",
    "print(u)\n",
    "print(u.cumsum(dim=-1))\n",
    "for i in out:\n",
    "    print(i, \"{0:b}\".format(int(i.item())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_matrix_fn(dA, dB, C, L, x_shape, dtype=torch.float16):\n",
    "    # dA = torch.exp(torch.einsum(\"bdl,dn->bldn\", dt, A))\n",
    "    # dB = torch.einsum(\"bdl,bnl->bldn\", dt, B.squeeze(1))\n",
    "    AttnMatrixOverCLS = torch.zeros((x_shape[0], x_shape[1], x_shape[2], x_shape[2])).to(dtype).to(dA.device) #BHLL: L vectors per batch and channel\n",
    "    for r in range(L):\n",
    "        for c in range(r+1):\n",
    "            curr_C = C[:,r,:]\n",
    "            currA = torch.ones((dA.shape[0],dA.shape[1],dA.shape[3]), dtype = dtype).to(dA.device)\n",
    "            if c < r:\n",
    "                for i in range(r-c):\n",
    "                    currA = currA*dA[:,:,r-i,:]\n",
    "            currB = dB[:,:,c,:]\n",
    "            AttnMatrixOverCLS[:,:,r,c] = torch.sum(curr_C*currA*currB, axis=-1)\n",
    "    return AttnMatrixOverCLS\n",
    "\n",
    "def knockout_matrix(seq_len: int, discrete_A: Tensor, discrete_B: Tensor, u: Tensor, C: Tensor, knocked_out_inputs: Iterable[int], affected_outputs: Iterable[int], dtype) -> List[Tensor]:\n",
    "    # _attn = materialize_ssm_attention(discrete_A, discrete_B, C, False)\n",
    "    attn = compute_attn_matrix_fn(discrete_A, discrete_B, C, seq_len, u.shape, dtype)\n",
    "    for i in affected_outputs:\n",
    "        for j in knocked_out_inputs:\n",
    "            attn[:, :, i, j] = 0\n",
    "    # u = u.transpose(2,1)\n",
    "    outputs = (attn @ u).squeeze(-1)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) 1\n",
      "tensor(3.) 11\n",
      "tensor(7.) 111\n",
      "tensor(15.) 1111\n",
      "tensor(20.) 10100\n"
     ]
    }
   ],
   "source": [
    "materialize_ssm_attention(A, B, C, False)\n",
    "out = knockout_matrix(T, A, B, u.unsqueeze(-1), C, [0,1,3], [4], torch.float)\n",
    "for i in out[0][0]:\n",
    "    print(i, \"{0:b}\".format(int(i.item())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from torch import Tensor, device\n",
    "\n",
    "\n",
    "def segsum(x: Tensor, device: Optional[device] = None) -> Tensor:\n",
    "    \"\"\"Stable segment sum calculation.\n",
    "\n",
    "    `exp(segsum(A))` produces a 1-semiseparable matrix, which is equivalent to a scalar SSM.\n",
    "\n",
    "    Source: https://github.com/state-spaces/mamba/blob/219f03c840d5a44e7d42e4e728134834fddccf45/mamba_ssm/modules/ssd_minimal.py#L23-L32\n",
    "    \"\"\"\n",
    "    T = x.size(-1)\n",
    "    x = repeat(x, \"... d -> ... d e\", e=T)\n",
    "    mask = torch.tril(torch.ones(T, T, dtype=torch.bool, device=device), diagonal=-1)\n",
    "    x = x.masked_fill(~mask, 0)\n",
    "    x_segsum = torch.cumsum(x, dim=-2)\n",
    "    mask = torch.tril(torch.ones(T, T, dtype=torch.bool, device=device), diagonal=0)\n",
    "    x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n",
    "    return x_segsum\n",
    "\n",
    "\n",
    "def mamba2_knockout(L,B,C,x, list_of_masks):\n",
    "    CBT = torch.einsum(\"bclhn, bcshn -> bhcls\", C, B)\n",
    "    print(CBT.shape)\n",
    "    attention_matrix = torch.einsum(\"bhcls, bhcls -> bclhs\", CBT, L)\n",
    "    # attention_matrix shape is: batch, chunk, seq_len , heads, seq_len\n",
    "    # To remove the attention *given* by idx1 to idx2 do :\n",
    "    # attention_matrix[:,:,idx1,:,idx2] = 0\n",
    "    # by this notion idx1 is always greater or equal to idx2\n",
    "    # attention_matrix[:, :, 11, :, 3] = 0\n",
    "    for idx1, idx2 in list_of_masks:\n",
    "        attention_matrix[:, :, idx1, :, idx2] = 0\n",
    "\n",
    "    out_by_atten = torch.einsum(\"bclhs, bcshp-> bclhp\", attention_matrix, x)\n",
    "    out_by_atten = rearrange(out_by_atten, 'b c l h p -> b (c l) h p')\n",
    "    return out_by_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 5, 5])\n",
      "tensor([[[[ 1.]],\n",
      "\n",
      "         [[ 3.]],\n",
      "\n",
      "         [[ 7.]],\n",
      "\n",
      "         [[13.]],\n",
      "\n",
      "         [[29.]]]])\n",
      "torch.Size([1, 5, 1, 1])\n",
      "1\n",
      "11\n",
      "111\n",
      "1101\n",
      "11101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b, c, l, h, n, p = 1, 1, 5, 1, 8, 1\n",
    "L = torch.ones((b, h, c, l, l)) #bhcls\n",
    "L = torch.tril(L)\n",
    "\n",
    "# bclhn, bcshn\n",
    "C = torch.ones((b, c, l, h, n))\n",
    "B = torch.ones((b, c, l, h, n))\n",
    "B = B / n\n",
    "u = torch.ones((b, c, l, h, p))\n",
    "for i in range(l):\n",
    "    u[0, 0, i, 0, 0] = 2**i\n",
    "\n",
    "knockout_list = [(3,1), (4,1)]\n",
    "\n",
    "out = mamba2_knockout(L,B,C,u, knockout_list)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "for i in range(l):\n",
    "    print(\"{0:b}\".format(int(out[0,i,0,0].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

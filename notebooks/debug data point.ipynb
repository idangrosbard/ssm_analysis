{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using causal_conv1d\n",
      "Not using causal_conv1d\n",
      "Not using causal_conv1d\n"
     ]
    }
   ],
   "source": [
    "from src.experiments.info_flow import InfoFlowConfig\n",
    "from src.types import TokenType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.types import MODEL_ARCH\n",
    "\n",
    "config = InfoFlowConfig(\n",
    "    model_arch=MODEL_ARCH.MAMBA2,\n",
    "    model_size=\"1.3B\",\n",
    "    window_size=9,\n",
    "    variation=\"v3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = config.get_prompt_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m get_tokenizer(config\u001b[38;5;241m.\u001b[39mmodel_arch, config\u001b[38;5;241m.\u001b[39mmodel_size)\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_prompt_row_index(data, \u001b[38;5;241m17102\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m num_to_masks, first_token \u001b[38;5;241m=\u001b[39m \u001b[43mget_num_to_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknockout_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m num_to_masks\n",
      "File \u001b[0;32m/home/yandex/DL20232024a/nirendy/repos/ssm_analysis/src/utils/logits.py:120\u001b[0m, in \u001b[0;36mget_num_to_masks\u001b[0;34m(prompt, tokenizer, window, knockout_source, knockout_target, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m first_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    119\u001b[0m last_idx \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 120\u001b[0m tok_start, tok_end \u001b[38;5;241m=\u001b[39m \u001b[43mfind_token_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m subject_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(tok_start, tok_end))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m subject_tokens:\n",
      "File \u001b[0;32m/home/yandex/DL20232024a/nirendy/repos/ssm_analysis/src/utils/logits.py:61\u001b[0m, in \u001b[0;36mfind_token_range\u001b[0;34m(tokenizer, token_array, substring)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Find the tokens corresponding to the given substring in token_array.\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m toks \u001b[38;5;241m=\u001b[39m decode_tokens(tokenizer, token_array)\n\u001b[0;32m---> 61\u001b[0m whole_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     62\u001b[0m char_loc \u001b[38;5;241m=\u001b[39m whole_string\u001b[38;5;241m.\u001b[39mindex(substring)\n\u001b[1;32m     63\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "from src.utils.logits import get_num_to_masks, get_prompt_row_index\n",
    "from src.utils.setup_models import get_tokenizer\n",
    "\n",
    "# debugging ││Error evaluating 17102 in window [0, 1, 2, 3, 4, 5, 6, 7, 8] with source last and target last: substring not found\n",
    "idx = 17102\n",
    "source = TokenType.last\n",
    "knockout_target = TokenType.last\n",
    "window = list(range(0, 9))\n",
    "\n",
    "tokenizer = get_tokenizer(config.model_arch, config.model_size)\n",
    "prompt = get_prompt_row_index(data, 17102)\n",
    "\n",
    "num_to_masks, first_token = get_num_to_masks(prompt, tokenizer, window, source, knockout_target, \"cpu\")\n",
    "\n",
    "num_to_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using causal_conv1d\n",
      "Not using causal_conv1d\n",
      "Not using causal_conv1d\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from hmac import new\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, assert_never, Dict, List, Tuple\n",
    "from torch import Tensor\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import pyrallis\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "from scripts.create_slurm_file import run_slurm\n",
    "from src.consts import (\n",
    "    FILTERATIONS,\n",
    "    MODEL_SIZES_PER_ARCH_TO_MODEL_ID,\n",
    "    PATHS,\n",
    ")\n",
    "from src.datasets.download_dataset import load_dataset, load_splitted_counter_fact\n",
    "from src.datasets.download_dataset import load_knowns_pd, get_hit_dataset\n",
    "from src.logit_utils import get_last_token_logits, logits_to_probs\n",
    "from src.models.model_interface import get_model_interface\n",
    "from src.types import DATASETS\n",
    "from src.types import MODEL_ARCH, SPLIT, DatasetArgs, TModelID\n",
    "from src.utils.setup_models import get_tokenizer_and_model\n",
    "from src.utils.slurm import submit_job\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    # model_arch: MODEL_ARCH = MODEL_ARCH.MINIMAL_MAMBA2_new\n",
    "    model_arch: MODEL_ARCH = MODEL_ARCH.MAMBA1\n",
    "    model_size: str = \"2.8B\"\n",
    "    dataset_args: DatasetArgs = pyrallis.field(\n",
    "        default=DatasetArgs(name=DATASETS.COUNTER_FACT, splits=\"all\"), is_mutable=True\n",
    "    )\n",
    "    filteration: str = FILTERATIONS.all_correct\n",
    "    _batch_size: int = 16  # Adjust based on GPU memory\n",
    "    output_file: Optional[Path] = None\n",
    "    with_slurm: bool = False\n",
    "    temperature = 1\n",
    "    top_k = 0\n",
    "    top_p = 1\n",
    "    window_size = 9\n",
    "    prompt_indices = [1,2,3,4,5]\n",
    "    knockout_map = {'last': ['last', 'first', \"subject\", \"relation\"], \n",
    "                    'subject': ['context', 'subject']}\n",
    "\n",
    "    output_dir: Optional[Path] = None\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        return (\n",
    "            1\n",
    "            if (\n",
    "                self.model_arch == MODEL_ARCH.MINIMAL_MAMBA2\n",
    "                or self.model_arch == MODEL_ARCH.MINIMAL_MAMBA2_new\n",
    "            )\n",
    "            else self._batch_size\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def model_id(self) -> TModelID:\n",
    "        return MODEL_SIZES_PER_ARCH_TO_MODEL_ID[self.model_arch][self.model_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_knockout(\n",
    "    block_source,\n",
    "    block_target,\n",
    "):\n",
    "    # Open and read the JSON file\n",
    "    data = pd.read_json(\n",
    "        PATHS.OUTPUT_DIR / \n",
    "        f'{args.model_id}/info_flow_test_top_outputs/ds={args.dataset_args.dataset_name}/ws={args.window_size}'\n",
    "        f'/block_{block_source}_target_{block_target}/outputs.json'\n",
    "    )\n",
    "\n",
    "    # Print the data\n",
    "    # print(data)\n",
    "    new_df = defaultdict(list)\n",
    "    for i, row in data.iterrows():\n",
    "        row = row[0][0]\n",
    "        # print(row)\n",
    "        new_df['token'].append(row[1])\n",
    "        new_df['prob'].append(row[2])\n",
    "        new_df['token_id'].append(row[0])\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "    return new_df\n",
    "\n",
    "def calc_correct(merged):\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    merged['correct'] = merged.apply(lambda row: row['token_id'] == tokenizer(row['target_true'])['input_ids'][0], axis=1)\n",
    "    print(f\"Correct: {merged['correct'].sum()}, Incorrect: {(~merged['correct']).sum()}\")\n",
    "    # filtered = merged[merged['correct']]\n",
    "    return merged\n",
    "\n",
    "def parse_outputs(p):\n",
    "    data = json.load(p.open('r'))\n",
    "    d = defaultdict(list)\n",
    "    for window, outputs in data.items():\n",
    "        for metric, output in outputs.items():\n",
    "            d[metric].append(output)\n",
    "            \n",
    "\n",
    "    return {\n",
    "        k: pd.DataFrame.from_dict(v).T\n",
    "        for k, v in d.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_flow_animation(\n",
    "    title: str,\n",
    "    output_path: Path,\n",
    "    prompts: pd.DataFrame,\n",
    "    probs_per_window: pd.DataFrame,\n",
    "    correct_per_window: pd.DataFrame,\n",
    "    point_size=15,\n",
    "    frames_per_transition=20,  # Number of intermediate frames between original timesteps\n",
    "    seconds_per_transition=1,  # Time in seconds for each transition\n",
    "):\n",
    "    # Parameters\n",
    "    first_frame = int(probs_per_window.columns[0])\n",
    "    interval = (seconds_per_transition * 1000) / frames_per_transition\n",
    "    frames_per_second = int(frames_per_transition / seconds_per_transition)\n",
    "\n",
    "    # Original data\n",
    "    correct = np.array(correct_per_window).T # shape (num_windows, num_points)\n",
    "    probs_aligned = np.array(probs_per_window).T # shape (num_windows, num_points)\n",
    "    base_probs = np.array(prompts[\"true_prob\"]) # shape (num_points,)\n",
    "    num_points = probs_aligned.shape[1]\n",
    "    num_timesteps = probs_aligned.shape[0]\n",
    "    accuracy = correct.sum(axis=1) / num_points\n",
    "\n",
    "    # Interpolation to create smoother transitions\n",
    "    new_num_timesteps = num_timesteps * frames_per_transition\n",
    "    probs_smooth = np.zeros((new_num_timesteps, num_points))\n",
    "\n",
    "    for i in range(num_timesteps - 1):\n",
    "        start_frame = probs_aligned[i]\n",
    "        end_frame = probs_aligned[i + 1]\n",
    "        for j in range(frames_per_transition):\n",
    "            alpha = j / frames_per_transition  # Linear interpolation factor\n",
    "            probs_smooth[i * frames_per_transition + j] = (\n",
    "                1 - alpha\n",
    "            ) * start_frame + alpha * end_frame\n",
    "\n",
    "    # Add the final frame to the end, frames_per_transition times\n",
    "    probs_smooth[-frames_per_transition:] = probs_aligned[-1]\n",
    "\n",
    "    # Create figure and scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    colors = np.where(correct, \"green\", \"red\")  # Green for True, Red for False\n",
    "    scat = ax.scatter(\n",
    "        base_probs, probs_smooth[0], s=point_size, c=colors[0], edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Base Probability\")\n",
    "    ax.set_ylabel(\"Knockout Probability\")\n",
    "\n",
    "    # Update function for animation\n",
    "    def update(frame):\n",
    "        scat.set_offsets(np.column_stack((base_probs, probs_smooth[frame])))\n",
    "        if frame % frames_per_transition == 0:\n",
    "            # change the color\n",
    "            current_og_frame = frame // frames_per_transition\n",
    "            scat.set_color(colors[int(current_og_frame)])\n",
    "            ax.set_title(\n",
    "                f\"{title}\\nProbabilities - Window {first_frame + current_og_frame}/{first_frame + num_timesteps-1} - Accuracy: {accuracy[current_og_frame]*100:.1f}%\"\n",
    "            )\n",
    "        return (scat,)\n",
    "\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(\n",
    "        fig, update, frames=new_num_timesteps, interval=interval, blit=True\n",
    "    )\n",
    "\n",
    "    # Display the animation in Jupyter Notebook\n",
    "    plt.close(fig)\n",
    "    ani.save(output_path, writer=\"imagemagick\", fps=frames_per_second)\n",
    "    # HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_combined(args: Args):\n",
    "    for block_source in ['last', 'subject']:\n",
    "        for block_target in ['last']:\n",
    "            outputs = parse_outputs(\n",
    "                PATHS.OUTPUT_DIR\n",
    "                / f\"{args.model_id}/info_flow_v7/ds={args.dataset_args.dataset_name}/ws={args.window_size}/block_{block_source}_target_{block_target}/outputs.json\"\n",
    "            )\n",
    "            \n",
    "            output_path = (\n",
    "                PATHS.RESULTS_DIR \n",
    "                / 'info_flow_animation'\n",
    "                / f\"{args.model_id.split('/')[1]}_{args.window_size}_{block_source}_{block_target}.gif\"\n",
    "            )\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            title = f\"{args.model_id.split('/')[1]} - ws={args.window_size} - source={block_source} - target={block_target}\"\n",
    "            create_info_flow_animation(\n",
    "                title, output_path, \n",
    "                prompts = get_hit_dataset(args.model_id, args.dataset_args).reset_index(drop=True),\n",
    "                correct_per_window = outputs['hit'],\n",
    "                probs_per_window = outputs['true_probs'],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba-130M-hf with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba-1.4B-hf with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba-2.8B-hf with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba2-130M with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba2-1.3b with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animation for state-spaces/mamba2-2.7B with window size 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "window_sizes = [9]\n",
    "for model_arch, model_size in [\n",
    "    (MODEL_ARCH.MAMBA1, \"130M\"),\n",
    "    (MODEL_ARCH.MAMBA1, \"1.4B\"),\n",
    "    (MODEL_ARCH.MAMBA1, \"2.8B\"),\n",
    "    (MODEL_ARCH.MINIMAL_MAMBA2_new, \"130M\"),\n",
    "    (MODEL_ARCH.MINIMAL_MAMBA2_new, \"1.3B\"),\n",
    "    (MODEL_ARCH.MINIMAL_MAMBA2_new, \"2.7B\"),\n",
    "]:\n",
    "    args.model_arch = model_arch\n",
    "    args.model_size = model_size\n",
    "    for window_size in window_sizes:\n",
    "        args.window_size = window_size\n",
    "\n",
    "        print(f\"Creating animation for {args.model_id} with window size {args.window_size}\")\n",
    "        all_combined(args)\n",
    "        \n",
    "        # display(all_combined(args))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

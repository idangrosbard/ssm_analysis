{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functools\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import src.plots as plots\n",
    "from src.consts import GRAPHS_ORDER, MODEL_SIZES_PER_ARCH_TO_MODEL_ID, PATHS\n",
    "from src.utils.logit_utils import decode_tokens\n",
    "from src.types import DATASETS, MODEL_ARCH, DatasetArgs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "\n",
    "MODEL_TO_HEATMAP_VERSION = {\n",
    "    MODEL_ARCH.MAMBA1: \"_v6\",\n",
    "    MODEL_ARCH.MINIMAL_MAMBA2_new: \"_v6\",\n",
    "}\n",
    "\n",
    "ds = DatasetArgs(name=DATASETS.COUNTER_FACT, splits=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_suffix_to_function = {\n",
    "    # '_simple': plots.plot_simple_heatmap,\n",
    "    '_simple_diff_fixed_0.3': functools.partial(plots.simple_diff_fixed, fixed_diff=0.3),\n",
    "    # '_minimal_title_simple_diff_fixed_0.3': functools.partial(plots.simple_diff_fixed, fixed_diff=0.3, minimal_title=True),\n",
    "    # '_simple_diff_fixed_0.2': functools.partial(plots.simple_diff_fixed, fixed_diff=0.2),\n",
    "    # '_simple_diff_fixed_0.3': functools.partial(plots.simple_diff_fixed, fixed_diff=0.3),\n",
    "    # '_robust': plots.plot_heatmap_robust,\n",
    "    # '_robust_diff': plots.plot_heatmap_robust_diff,\n",
    "    # '_diff_symlog': plots.plot_heatmap_diff_symlog,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c617c753030420cad45fe39917e1dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pattern = r\"/state-spaces/(?P<model_id>[\\w\\.-]+)/heatmap(?P<version>_v\\d+)/ds=(?P<dataset>[\\w_]+)/ws=(?P<window_size>\\d+)/idx=(?P<prompt_idx>\\d+)\\.npy\"\n",
    "\n",
    "for p in tqdm(list(PATHS.OUTPUT_DIR.rglob('*.npy'))[:]):\n",
    "    match = re.search(pattern, str(p))\n",
    "    if match:\n",
    "        details = match.groupdict()\n",
    "        if details['version'] != '_v6': continue\n",
    "        model_id = details['model_id']\n",
    "        # if 'mamba-1.4B' not in model_id: continue\n",
    "        # if 'mamba-2.8B' not in model_id: continue\n",
    "        window_size = details['window_size']\n",
    "        prompt_idx = int(details['prompt_idx'])\n",
    "        \n",
    "        if model_id not in models_data:\n",
    "            print(f\"fetching data for {model_id}\")\n",
    "            original_res, attn_res = [\n",
    "                pd.read_parquet(\n",
    "                    PATHS.OUTPUT_DIR\n",
    "                    / 'state-spaces'\n",
    "                    / model_id\n",
    "                    / \"data_construction\"\n",
    "                    / f\"ds={details['dataset']}\"\n",
    "                    / f\"entire_results_{\"attention\" if attention else \"original\"}.parquet\"\n",
    "                )\n",
    "                for attention in [True, False]\n",
    "            ]\n",
    "\n",
    "            mask = (original_res[\"hit\"] == attn_res[\"hit\"]) & (attn_res[\"hit\"] == True)\n",
    "            models_data[model_id] = attn_res[mask]\n",
    "        \n",
    "        data = models_data[model_id]\n",
    "        prompt = data.loc[prompt_idx, \"prompt\"]\n",
    "        true_word = data.loc[prompt_idx, \"target_true\"]\n",
    "        base_prob = data.loc[prompt_idx, \"true_prob\"]\n",
    "        tokens = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "        input_ids = tokens.input_ids\n",
    "        toks = decode_tokens(tokenizer, input_ids[0])\n",
    "        last_tok = toks[-1]\n",
    "        toks[-1] = toks[-1] + \"*\"\n",
    "        \n",
    "        prob_mat = np.load(p)\n",
    "        for plot_suffix, plot_func in plot_suffix_to_function.items():\n",
    "            fig, _ = plot_func(\n",
    "                prob_mat=prob_mat,\n",
    "                model_id=model_id,\n",
    "                window_size=window_size,\n",
    "                last_tok=last_tok,\n",
    "                base_prob=base_prob,\n",
    "                true_word=true_word,\n",
    "                toks=toks,\n",
    "            )\n",
    "            plt.savefig(p.parent / f\"idx={prompt_idx}{plot_suffix}.png\", bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "        # break\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae91499db0e4d618d021528e42b8613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_all_heatmaps(suffix):\n",
    "    pattern = f\"idx=*{suffix}.png\"\n",
    "    for i, size_cat in enumerate(['small', 'medium', 'large']):\n",
    "        requested_models = GRAPHS_ORDER[2*i:2*(i+1)]\n",
    "        for requested_ws in [1,5,9]:        \n",
    "            prompts_ws_models = defaultdict(lambda: defaultdict(list))\n",
    "            ws_opts = set()\n",
    "\n",
    "            img_width = 0\n",
    "            img_height = 0\n",
    "            for model, size in requested_models:\n",
    "                model_id = MODEL_SIZES_PER_ARCH_TO_MODEL_ID[model][size]\n",
    "                model_dir = (\n",
    "                    PATHS.OUTPUT_DIR / f\"{model_id}/heatmap{MODEL_TO_HEATMAP_VERSION[model]}\"\n",
    "                )\n",
    "                for file in model_dir.rglob(pattern):\n",
    "                    \n",
    "                    window_size = re.search(r\"ws=(\\d+)\", str(file)).group(1)\n",
    "                    \n",
    "                    if match := re.search(fr\"idx=(\\d+){suffix}.png\", str(file)):\n",
    "                        prompt_id = match.group(1)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    if int(window_size) != requested_ws: continue\n",
    "                    \n",
    "                    img = Image.open(file)\n",
    "                    img_width = max(img_width, img.width)\n",
    "                    img_height = max(img_height, img.height)\n",
    "\n",
    "                    prompts_ws_models[prompt_id][window_size].append(\n",
    "                        (model_id.split(\"/\")[1], img)\n",
    "                    )\n",
    "                    ws_opts.add(window_size)\n",
    "\n",
    "                padding = 10\n",
    "                # title_height = 30  # Height for titles\n",
    "                title_height = 0  # Height for titles\n",
    "\n",
    "                # Calculate grid size\n",
    "                num_rows = len(prompts_ws_models) * len(ws_opts)\n",
    "                num_cols = len(requested_models)\n",
    "\n",
    "                canvas_width = num_cols * (img_width + padding)\n",
    "                canvas_height = num_rows * (img_height + title_height + padding)\n",
    "\n",
    "                # Create a blank image\n",
    "                combined_image = Image.new(\"RGB\", (canvas_width, canvas_height), \"white\")\n",
    "                draw = ImageDraw.Draw(combined_image)\n",
    "\n",
    "                # Positioning variables\n",
    "                y_offset = 0  # Tracks vertical position on canvas\n",
    "\n",
    "                # Populate canvas with images and titles\n",
    "                for prompt_id, ws_models in prompts_ws_models.items():\n",
    "                    for window_size, models in ws_models.items():\n",
    "                        x_offset = 0  # Reset horizontal position for each row\n",
    "                        for model_name, img in models:\n",
    "                            # Add image to canvas\n",
    "                            combined_image.paste(\n",
    "                                img.resize((img_width, img_height)),\n",
    "                                (x_offset, y_offset + title_height),\n",
    "                            )\n",
    "\n",
    "                            # Add title above the image\n",
    "                            # title_text = f\"{model_name} (ws={window_size})\"\n",
    "                            # draw.text((x_offset, y_offset), title_text, fill=\"black\")\n",
    "\n",
    "                            # Update x_offse\\t for next column\n",
    "                            x_offset += img_width + padding\n",
    "\n",
    "                        # Update y_offset for the next row\n",
    "                        y_offset += img_height + title_height + padding\n",
    "\n",
    "                # Save or show the combined image\n",
    "                base_dir = PATHS.RESULTS_DIR / \"combined_heatmaps\" / suffix\n",
    "                base_dir.mkdir(exist_ok=True, parents=True)\n",
    "                combined_image.save(base_dir / f\"ws={requested_ws}_{size_cat}.png\")\n",
    "                # combined_image.show()\n",
    "\n",
    "\n",
    "for suffix in tqdm(list(plot_suffix_to_function.keys())):\n",
    "    # Example usage\n",
    "    display_all_heatmaps(suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

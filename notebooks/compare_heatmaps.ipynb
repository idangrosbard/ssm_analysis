{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from src.consts import GRAPHS_ORDER, MODEL_SIZES_PER_ARCH_TO_MODEL_ID, PATHS, reverse_model_id\n",
    "from src.datasets.download_dataset import get_hit_dataset\n",
    "from src.plots.heatmaps import simple_diff_fixed\n",
    "from src.types import DATASETS, MODEL_ARCH, DatasetArgs\n",
    "from src.utils.logits import decode_tokens, get_prompt_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "\n",
    "MODEL_TO_HEATMAP_VERSION = {\n",
    "    MODEL_ARCH.MAMBA1: \"_v7\",\n",
    "    MODEL_ARCH.MINIMAL_MAMBA2_new: \"_v7\",\n",
    "}\n",
    "\n",
    "ds = DatasetArgs(name=DATASETS.COUNTER_FACT, splits=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {}\n",
    "models_tokenizers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(arch_original: str):\n",
    "    if arch_original in models_tokenizers:\n",
    "        return models_tokenizers[arch_original]\n",
    "    if arch_original == \"state-spaces\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    elif arch_original == \"tiiuae\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-mamba-7b\")\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {arch_original}\")\n",
    "    models_tokenizers[arch_original] = tokenizer\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift(arch_original: str) -> int:\n",
    "    if arch_original == \"state-spaces\":\n",
    "        return 0\n",
    "    elif arch_original == \"tiiuae\":\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {arch_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_suffix_to_function = {\n",
    "    # '_simple': plots.plot_simple_heatmap,\n",
    "    \"_simple_diff_fixed_0.3\": functools.partial(simple_diff_fixed, fixed_diff=0.3),\n",
    "    # \"_simple_diff_fixed_0.9\": functools.partial(plots.simple_diff_fixed, fixed_diff=0.9),\n",
    "    # '_minimal_title_simple_diff_fixed_0.3': functools.partial(plots.simple_diff_fixed, fixed_diff=0.3, minimal_title=True),\n",
    "    # '_simple_diff_fixed_0.2': functools.partial(plots.simple_diff_fixed, fixed_diff=0.2),\n",
    "    # '_simple_diff_fixed_0.3': functools.partial(plots.simple_diff_fixed, fixed_diff=0.3),\n",
    "    # '_robust': plots.plot_heatmap_robust,\n",
    "    # '_robust_diff': plots.plot_heatmap_robust_diff,\n",
    "    # '_diff_symlog': plots.plot_heatmap_diff_symlog,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a4695b56a4487c9b8fa19fbfada1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern = r\"/(?P<arch_original>[\\w\\.-]+)/(?P<model_id>[\\w\\.-]+)/heatmap(?P<version>_v\\d+)/ds=(?P<dataset>[\\w_]+)/ws=(?P<window_size>\\d+)/idx=(?P<prompt_idx>\\d+)\\.npy\"\n",
    "\n",
    "candidate_files: list[tuple[Path, dict]] = []\n",
    "\n",
    "for p in PATHS.OUTPUT_DIR.rglob(\"*.npy\"):\n",
    "    match = re.search(pattern, str(p))\n",
    "    if match:\n",
    "        details = match.groupdict()\n",
    "        if details[\"version\"] != \"_v8\":\n",
    "            continue\n",
    "        # if details[\"window_size\"] != \"9\":\n",
    "        #     continue\n",
    "        if details[\"model_id\"] != \"falcon-mamba-7b\":\n",
    "            # if details[\"model_id\"] != \"mamba-2.8B-hf\":\n",
    "            # if details[\"model_id\"] != \"mamba2-2.7B\":\n",
    "            continue\n",
    "\n",
    "        candidate_files.append((p, details))\n",
    "\n",
    "for p, details in tqdm(candidate_files):\n",
    "    model_arch, model_size = reverse_model_id(details[\"model_id\"])\n",
    "    model_id = MODEL_SIZES_PER_ARCH_TO_MODEL_ID[model_arch][model_size]\n",
    "    # if 'mamba-1.4B' not in model_id: continue\n",
    "    # if 'mamba-2.8B' not in model_id: continue\n",
    "    window_size = details[\"window_size\"]\n",
    "    prompt_idx = int(details[\"prompt_idx\"])\n",
    "\n",
    "    if model_id not in models_data:\n",
    "        ds = DatasetArgs(name=DATASETS.COUNTER_FACT, splits=\"all\")\n",
    "        assert ds.dataset_name == details[\"dataset\"]\n",
    "        models_data[model_id] = get_hit_dataset(model_id, ds)\n",
    "\n",
    "    data = models_data[model_id]\n",
    "    tokenizer = get_tokenizer(details[\"arch_original\"])\n",
    "    index_shift = get_shift(details[\"arch_original\"])\n",
    "    prompt = get_prompt_row(data, prompt_idx)\n",
    "    input_ids = prompt.input_ids(tokenizer, \"cpu\")\n",
    "    toks = decode_tokens(tokenizer, input_ids[0])\n",
    "    last_tok = toks[-1]\n",
    "    toks[-1] = toks[-1] + \"*\"\n",
    "\n",
    "    prob_mat = np.load(p)\n",
    "    for plot_suffix, plot_func in plot_suffix_to_function.items():\n",
    "        fig, _ = plot_func(\n",
    "            prob_mat=prob_mat,\n",
    "            model_id=model_id,\n",
    "            window_size=window_size,\n",
    "            last_tok=last_tok,\n",
    "            base_prob=prompt.base_prob,\n",
    "            true_word=prompt.true_word,\n",
    "            toks=toks,\n",
    "        )\n",
    "        plt.savefig(p.parent / f\"idx={prompt_idx + index_shift}{plot_suffix}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae91499db0e4d618d021528e42b8613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_all_heatmaps(suffix):\n",
    "    pattern = f\"idx=*{suffix}.png\"\n",
    "    for i, size_cat in enumerate([\"small\", \"medium\", \"large\"]):\n",
    "        requested_models = GRAPHS_ORDER[2 * i : 2 * (i + 1)]\n",
    "        for requested_ws in [1, 5, 9]:\n",
    "            prompts_ws_models = defaultdict(lambda: defaultdict(list))\n",
    "            ws_opts = set()\n",
    "\n",
    "            img_width = 0\n",
    "            img_height = 0\n",
    "            for model, size in requested_models:\n",
    "                model_id = MODEL_SIZES_PER_ARCH_TO_MODEL_ID[model][size]\n",
    "                model_dir = PATHS.OUTPUT_DIR / f\"{model_id}/heatmap{MODEL_TO_HEATMAP_VERSION[model]}\"\n",
    "                for file in model_dir.rglob(pattern):\n",
    "                    window_size = re.search(r\"ws=(\\d+)\", str(file)).group(1)\n",
    "\n",
    "                    if match := re.search(rf\"idx=(\\d+){suffix}.png\", str(file)):\n",
    "                        prompt_id = match.group(1)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if int(window_size) != requested_ws:\n",
    "                        continue\n",
    "\n",
    "                    img = Image.open(file)\n",
    "                    img_width = max(img_width, img.width)\n",
    "                    img_height = max(img_height, img.height)\n",
    "\n",
    "                    prompts_ws_models[prompt_id][window_size].append((model_id.split(\"/\")[1], img))\n",
    "                    ws_opts.add(window_size)\n",
    "\n",
    "                padding = 10\n",
    "                # title_height = 30  # Height for titles\n",
    "                title_height = 0  # Height for titles\n",
    "\n",
    "                # Calculate grid size\n",
    "                num_rows = len(prompts_ws_models) * len(ws_opts)\n",
    "                num_cols = len(requested_models)\n",
    "\n",
    "                canvas_width = num_cols * (img_width + padding)\n",
    "                canvas_height = num_rows * (img_height + title_height + padding)\n",
    "\n",
    "                # Create a blank image\n",
    "                combined_image = Image.new(\"RGB\", (canvas_width, canvas_height), \"white\")\n",
    "                draw = ImageDraw.Draw(combined_image)\n",
    "\n",
    "                # Positioning variables\n",
    "                y_offset = 0  # Tracks vertical position on canvas\n",
    "\n",
    "                # Populate canvas with images and titles\n",
    "                for prompt_id, ws_models in prompts_ws_models.items():\n",
    "                    for window_size, models in ws_models.items():\n",
    "                        x_offset = 0  # Reset horizontal position for each row\n",
    "                        for model_name, img in models:\n",
    "                            # Add image to canvas\n",
    "                            combined_image.paste(\n",
    "                                img.resize((img_width, img_height)),\n",
    "                                (x_offset, y_offset + title_height),\n",
    "                            )\n",
    "\n",
    "                            # Add title above the image\n",
    "                            # title_text = f\"{model_name} (ws={window_size})\"\n",
    "                            # draw.text((x_offset, y_offset), title_text, fill=\"black\")\n",
    "\n",
    "                            # Update x_offse\\t for next column\n",
    "                            x_offset += img_width + padding\n",
    "\n",
    "                        # Update y_offset for the next row\n",
    "                        y_offset += img_height + title_height + padding\n",
    "\n",
    "                # Save or show the combined image\n",
    "                base_dir = PATHS.RESULTS_DIR / \"combined_heatmaps\" / suffix\n",
    "                base_dir.mkdir(exist_ok=True, parents=True)\n",
    "                combined_image.save(base_dir / f\"ws={requested_ws}_{size_cat}.png\")\n",
    "                # combined_image.show()\n",
    "\n",
    "\n",
    "for suffix in tqdm(list(plot_suffix_to_function.keys())):\n",
    "    # Example usage\n",
    "    display_all_heatmaps(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

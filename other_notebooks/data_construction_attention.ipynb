{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027074b6-5c83-4d0e-a2a3-ce8d45120563",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8007d7d-e7dc-4b46-adf5-0bb45a224ff1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from mamba2mini import Mamba2LMHeadModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb06e7-b843-4a34-a64c-484371f60658",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name = \"state-spaces/mamba2-1.3b\"\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad380d-9c8c-4e38-87ae-e4120b203893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to set correct caching directories\n",
    "\n",
    "# hf_dir = XXX\n",
    "# tri_dir = YYY\n",
    "# xdg_dir = ZZZ\n",
    "# os.environ['HF_HOME'] = hf_dir\n",
    "# os.environ['TRITON_CACHE_DIR'] = tri_dir\n",
    "# os.environ['XDG_CACHE_HOME'] = xdg_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbecbdfd-2681-4b51-9551-a10322e643b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f88caa-c563-4c5d-a7ba-d225796f2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_parquet('original_data.parquet')\n",
    "original_data['true_prob'] = 0.0\n",
    "original_data['max_prob'] = 0.0\n",
    "original_data['hit'] = False\n",
    "original_data['pred'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1e445-a3cf-4822-adde-c96df746e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", cache_dir=hf_dir, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f7315-890d-423f-a275-27cd03873c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mamba2LMHeadModel.from_pretrained(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713703b-3446-409e-a139-45d58d207b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(seed)\n",
    "model.eval()\n",
    "temperature = 1\n",
    "top_k = 0\n",
    "top_p = 1\n",
    "attention=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b5c00-6520-4a12-b43f-23a1a2aac3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_eval(temperature, top_k, top_p, batch_start, batch_end, attention, print_period=1000):\n",
    "    prompts = list(original_data.loc[batch_start:batch_end-1, 'prompt'].values)\n",
    "    true_word = list(original_data.loc[batch_start:batch_end-1, 'target_true'].values)\n",
    "    true_token = tokenizer(true_word, return_tensors=\"pt\", padding=True)\n",
    "    true_id = true_token.input_ids.to(device='cpu')\n",
    "    tokens = tokenizer(prompts, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = tokens.input_ids.to(device=device)\n",
    "    max_new_length = input_ids.shape[1] + 1\n",
    "    fn = lambda: model.generate_single(\n",
    "        input_ids=input_ids,\n",
    "        max_new_length=max_new_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        eos_token_id=tokenizer.eos_token,\n",
    "        attention=attention,\n",
    "    )\n",
    "    out = fn()\n",
    "    next_token_probs = out[-1].detach().cpu().numpy()\n",
    "    max_idx = np.argmax(next_token_probs, axis=1)\n",
    "    row_idx = np.arange(next_token_probs.shape[0])\n",
    "    preds = [tokenizer.decode([t]) for t in max_idx]\n",
    "    original_data.loc[batch_start:batch_end-1, 'true_prob'] = next_token_probs[row_idx, true_id[:, 0]]\n",
    "    original_data.loc[batch_start:batch_end-1, 'max_prob'] = next_token_probs[row_idx, max_idx]\n",
    "    original_data.loc[batch_start:batch_end-1, 'hit'] = original_data.loc[batch_start:batch_end-1, 'true_prob'] == original_data.loc[batch_start:batch_end-1, 'max_prob']\n",
    "    original_data.loc[batch_start:batch_end-1, 'pred'] = preds\n",
    "    if (batch_start+1) % print_period == 0:\n",
    "        print(f'Finished batch [{batch_start}:{batch_end-1}]')\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8dea4-3e5f-42ed-a1da-5dde4e93d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "N = len(original_data)\n",
    "batches = list(np.arange(0, N, batch_size)) + [N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b59a03-252f-4e2c-8df4-79e0178cc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_eval(temperature, top_k, top_p, batches[len(batches)-2], batches[len(batches)-1], attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f70f9-1d0e-4565-850b-e1f0b459837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batches)-2):\n",
    "    forward_eval(temperature, top_k, top_p, batches[i], batches[i+1], attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531338e-5214-44fe-921f-687c5377ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d750b-2b95-431d-973c-fed290b78d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['hit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf548c9-9b07-48a1-be43-65e13927ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.to_parquet('entire_results_attention.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

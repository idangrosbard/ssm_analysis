{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d12c01-8b38-4586-b041-7637af3413c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c6a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991823d8-9a67-4b70-a0a8-b6aba08a4c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7a1da13d2c90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce53b5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/yandex/DL20232024a/nirendy/repos/ADL_2/venv/lib/python3.12/site-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.consts import FILTERATIONS\n",
    "from src.datasets.download_dataset import load_splitted_counter_fact\n",
    "from tqdm import tqdm\n",
    "from src.types import MODEL_ARCH\n",
    "from src.models.model_interface import get_model_interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206e4e3b-ee97-499c-9b56-8497376df6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\"\n",
    "# model_name = \"state-spaces/mamba2-1.3b\"\n",
    "seed = 0\n",
    "n_layers = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf46fce-ad95-48a0-8236-c7450ed915ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to set correct caching directories\n",
    "\n",
    "# hf_dir = XXX\n",
    "# tri_dir = YYY\n",
    "# xdg_dir = ZZZ\n",
    "# os.environ['HF_HOME'] = hf_dir\n",
    "# os.environ['TRITON_CACHE_DIR'] = tri_dir\n",
    "# os.environ['XDG_CACHE_HOME'] = xdg_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772ab14-2fe6-4728-aac4-3566978222ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bddfe8-3106-4672-957c-6fd3973f272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_res = pd.read_parquet('entire_results_original.parquet')\n",
    "attn_res = pd.read_parquet('entire_results_attention.parquet')\n",
    "mask = (original_res['hit'] == attn_res['hit']) & (attn_res['hit'] == True)\n",
    "data = attn_res[mask]\n",
    "n_prompts = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247085fd-46d9-44c5-b573-6dd738215619",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analysis Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb25bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = MODEL_ARCH.MINIMAL_MAMBA2_new\n",
    "model_interface = get_model_interface(model_arch, model_size=\"130M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d02880",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(seed)\n",
    "# model.eval()\n",
    "temperature = 1\n",
    "top_k = 0\n",
    "top_p = 1\n",
    "attention = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model_interface.tokenizer\n",
    "device = model_interface.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe77753-8a11-4085-8576-ee1ce38ad9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/google-research/google-research/blob/master/dissecting_factual_predictions/utils.py \n",
    "def decode_tokens(tokenizer, token_array):\n",
    "    if hasattr(token_array, \"shape\") and len(token_array.shape) > 1:\n",
    "        return [decode_tokens(tokenizer, row) for row in token_array]\n",
    "    return [tokenizer.decode([t]) for t in token_array]\n",
    "\n",
    "def find_token_range(tokenizer, token_array, substring):\n",
    "    \"\"\"Find the tokens corresponding to the given substring in token_array.\"\"\"\n",
    "    toks = decode_tokens(tokenizer, token_array)\n",
    "    whole_string = \"\".join(toks)\n",
    "    char_loc = whole_string.index(substring)\n",
    "    loc = 0\n",
    "    tok_start, tok_end = None, None\n",
    "    for i, t in enumerate(toks):\n",
    "        loc += len(t)\n",
    "        if tok_start is None and loc > char_loc:\n",
    "            tok_start = i\n",
    "        if tok_end is None and loc >= char_loc + len(substring):\n",
    "            tok_end = i + 1\n",
    "            break\n",
    "    return (tok_start, tok_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e2b7b0-2074-40b2-9f82-e9e0c4e1959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_eval(temperature, top_k, top_p, prompt_idx, window, block=None):\n",
    "    prompt = data.loc[prompt_idx, 'prompt']\n",
    "    true_word = data.loc[prompt_idx, 'target_true']\n",
    "    base_prob = data.loc[prompt_idx, 'true_prob']\n",
    "    true_token = tokenizer(true_word, return_tensors=\"pt\", padding=True)\n",
    "    true_id = true_token.input_ids.to(device='cpu')\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = tokens.input_ids.to(device=device)\n",
    "    max_new_length = input_ids.shape[1] + 1\n",
    "    last_idx = input_ids.shape[1] - 1\n",
    "    num_to_masks = {}\n",
    "    first_token = False\n",
    "\n",
    "    tok_start, tok_end = find_token_range(tokenizer, input_ids[0], data.loc[prompt_idx, 'subject'])\n",
    "    subject_tokens = list(range(tok_start, tok_end))\n",
    "    if 0 in subject_tokens:\n",
    "        first_token = True\n",
    "    if block not in ('subject', 'relation'):\n",
    "        blocked_idx = [last_idx]\n",
    "    else:\n",
    "        if block == 'subject':\n",
    "            blocked_idx = subject_tokens\n",
    "        else:\n",
    "            blocked_idx = [i for i in range(last_idx + 1) if i not in subject_tokens]\n",
    "        \n",
    "    for layer in window:\n",
    "        for idx in blocked_idx:\n",
    "            if num_to_masks.get(layer) == None:\n",
    "                num_to_masks[layer] = [(last_idx, idx)]\n",
    "            else:\n",
    "                num_to_masks[layer].append((last_idx, idx))\n",
    "    \n",
    "    next_token_probs = model_interface.generate_logits(\n",
    "        input_ids=input_ids,\n",
    "        attention=True,\n",
    "        num_to_masks=num_to_masks,\n",
    "    )\n",
    "    max_prob = np.max(next_token_probs, axis=1)[0]\n",
    "    true_prob = next_token_probs[0, true_id[:, 0]]\n",
    "    torch.cuda.empty_cache()\n",
    "    return (true_prob == max_prob, (true_prob - base_prob) * 100.0 / base_prob, first_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b79e4a8-b3d0-4a20-9bf5-dd06c5d82663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(temperature, top_k, top_p, prompt_indices, windows, block=None, print_period=500):\n",
    "    counts_w_first = np.zeros((len(windows)))\n",
    "    counts_wo_first = np.zeros((len(windows)))\n",
    "    diffs_w_first = np.zeros((len(windows)))\n",
    "    diffs_wo_first = np.zeros((len(windows)))\n",
    "    w_first = 0\n",
    "    for i, window in enumerate(windows):\n",
    "        print('---------------------------------------------------------------')\n",
    "        print(f'Starting window {i}: {window}')\n",
    "        for j, prompt_idx in enumerate(prompt_indices):\n",
    "            hit, diff, first = forward_eval(temperature, top_k, top_p, prompt_idx, window, block)\n",
    "            if first:\n",
    "                if i == 0:\n",
    "                    w_first += 1\n",
    "                counts_w_first[i] += hit\n",
    "                diffs_w_first[i] += diff\n",
    "            else:\n",
    "                counts_wo_first[i] += hit\n",
    "                diffs_wo_first[i] += diff\n",
    "            if (j+1) % print_period == 0:\n",
    "                print(f'Finished prompt {j}')\n",
    "    counts = counts_w_first + counts_wo_first\n",
    "    diffs = diffs_w_first + diffs_wo_first\n",
    "    return (counts / n_prompts, diffs / n_prompts,\n",
    "            counts_w_first / w_first, diffs_w_first / w_first,\n",
    "            counts_wo_first / (n_prompts - w_first), diffs_wo_first / (n_prompts - w_first))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce36842-7dee-499c-aa19-7795ac4f2417",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experiments - no blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab884f6-aa44-4efe-b225-2292ea54c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "Starting window 0: []\n",
      "Finished prompt 499\n"
     ]
    }
   ],
   "source": [
    "prompt_indices = list(data.index)\n",
    "windows = [[]]\n",
    "no_block_acc, no_block_diff, _, _, _, _ = evaluate(temperature, top_k, top_p, prompt_indices, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edde671c-c013-4c81-8b61-9220df39d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(no_block_acc)\n",
    "print(no_block_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427bcff-ebb7-461b-be63-890360d11ac7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experiments - window size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e75845-b97b-488f-a22b-52442934dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 9\n",
    "prompt_indices = list(data.index)\n",
    "windows = [list(range(i, i + window_size)) for i in range(0, n_layers - window_size + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a232af-93b2-41df-ad6a-88b07873b628",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d27e2-9129-4e0f-9521-ba1d592d2c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "Starting window 0: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 1: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 2: [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 3: [3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 4: [4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 5: [5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 6: [6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 7: [7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 8: [8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 9: [9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 10: [10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 11: [11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 12: [12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 13: [13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 14: [14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 15: [15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 16: [16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 17: [17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 18: [18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 19: [19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 20: [20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 21: [21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Finished prompt 499\n",
      "---------------------------------------------------------------\n",
      "Starting window 22: [22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "last_acc, last_diff, last_wf_acc, last_wf_diff, last_wof_acc, last_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                       prompt_indices, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caef4e-712b-4b38-90b2-fcc72ee45a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(last_acc)\n",
    "df.to_parquet(f'block_last_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_diff)\n",
    "df.to_parquet(f'block_last_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wf_acc)\n",
    "df.to_parquet(f'block_last_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wf_diff)\n",
    "df.to_parquet(f'block_last_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wof_acc)\n",
    "df.to_parquet(f'block_last_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wof_diff)\n",
    "df.to_parquet(f'block_last_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c26fe6-a511-487a-82e5-c56341506ab3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59345db-02aa-44f5-bd3e-21895bd2a416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_acc, sub_diff, sub_wf_acc, sub_wf_diff, sub_wof_acc, sub_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                 prompt_indices, windows, block='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259bf5b-0498-48e8-b988-624bf2c15250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sub_acc)\n",
    "df.to_parquet(f'block_subject_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_diff)\n",
    "df.to_parquet(f'block_subject_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wf_acc)\n",
    "df.to_parquet(f'block_subject_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wf_diff)\n",
    "df.to_parquet(f'block_subject_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wof_acc)\n",
    "df.to_parquet(f'block_subject_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wof_diff)\n",
    "df.to_parquet(f'block_subject_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5795a0a-957d-4093-b5fd-0392f45fe165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9720999-a5b0-4d76-9419-a963beee2f2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_acc, rel_diff, rel_wf_acc, rel_wf_diff, rel_wof_acc, rel_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                 prompt_indices, windows, block='relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0fa9a-93bd-44f4-ad61-d2c51ed26de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rel_acc)\n",
    "df.to_parquet(f'block_relation_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_diff)\n",
    "df.to_parquet(f'block_relation_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wf_acc)\n",
    "df.to_parquet(f'block_relation_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wf_diff)\n",
    "df.to_parquet(f'block_relation_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wof_acc)\n",
    "df.to_parquet(f'block_relation_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wof_diff)\n",
    "df.to_parquet(f'block_relation_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57709b1f-166d-42b5-8869-5cb665780ddc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experiments - window size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e2c9e-bab7-4393-bfae-58fd954e80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "prompt_indices = list(data.index)\n",
    "windows = [list(range(i, i + window_size)) for i in range(0, n_layers - window_size + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d4cf2-f94f-4d03-948d-9d2b48ffaaae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832f9d7-b17a-4d7b-b704-20ea3cf6effb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_acc, last_diff, last_wf_acc, last_wf_diff, last_wof_acc, last_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                       prompt_indices, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03582e-500c-4c0d-9a2f-90dc1ee6932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(last_acc)\n",
    "df.to_parquet(f'block_last_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_diff)\n",
    "df.to_parquet(f'block_last_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wf_acc)\n",
    "df.to_parquet(f'block_last_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wf_diff)\n",
    "df.to_parquet(f'block_last_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wof_acc)\n",
    "df.to_parquet(f'block_last_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(last_wof_diff)\n",
    "df.to_parquet(f'block_last_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196a37e-4a8f-4b83-8b5b-ba637b486762",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58208397-15bf-4ef5-93c3-3f8615a3bb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_acc, sub_diff, sub_wf_acc, sub_wf_diff, sub_wof_acc, sub_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                 prompt_indices, windows, block='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3b753-894b-4826-ad0e-0ed8b5eb462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sub_acc)\n",
    "df.to_parquet(f'block_subject_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_diff)\n",
    "df.to_parquet(f'block_subject_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wf_acc)\n",
    "df.to_parquet(f'block_subject_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wf_diff)\n",
    "df.to_parquet(f'block_subject_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wof_acc)\n",
    "df.to_parquet(f'block_subject_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(sub_wof_diff)\n",
    "df.to_parquet(f'block_subject_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a3b26-4b95-419d-8ae9-be9792fcb0a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Block relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dabbac2-bbed-4d5d-8ff4-b822660f3ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_acc, rel_diff, rel_wf_acc, rel_wf_diff, rel_wof_acc, rel_wof_diff = evaluate(temperature, top_k, top_p, \n",
    "                                                                                 prompt_indices, windows, block='relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b9492-6ebe-41b7-bc2d-7d531d5cadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rel_acc)\n",
    "df.to_parquet(f'block_relation_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_diff)\n",
    "df.to_parquet(f'block_relation_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wf_acc)\n",
    "df.to_parquet(f'block_relation_wf_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wf_diff)\n",
    "df.to_parquet(f'block_relation_wf_diff_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wof_acc)\n",
    "df.to_parquet(f'block_relation_wof_acc_ws={window_size}.parquet')\n",
    "df = pd.DataFrame(rel_wof_diff)\n",
    "df.to_parquet(f'block_relation_wof_diff_ws={window_size}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a6df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
